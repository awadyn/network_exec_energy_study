{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d0cf07",
   "metadata": {},
   "source": [
    "## Merging of Per-Core Logs\n",
    "### Can we assume the following about per-core behavior: \n",
    "#### If all cores of a running experiment do similar work, then their individual behaviors - as exposed by their per-core logs - are similar to each other, and hence, the behavior of all cores can be merged into an overall behavior of the full experimental run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9d5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc046171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eigen_analysis\n",
    "\n",
    "cols = eigen_analysis.LINUX_COLS\n",
    "time_unit = eigen_analysis.TIME_CONVERSION_khz\n",
    "joules_unit = eigen_analysis.JOULE_CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b6ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all itrs explored for some (dvfs, qps) pair\n",
    "def list_itrs(rdtsc_dirname):\n",
    "    itrs = []\n",
    "    for file in os.listdir(rdtsc_dirname):\n",
    "        tags = file.split('_')\n",
    "        itr = tags[1]\n",
    "        itrs.append(itr)\n",
    "    itrs = list(set(itrs))\n",
    "    return itrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392bbe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rdtsc_from_summary(summary_file, sys, run, itr, dvfs, rapl, qps):\n",
    "    df = pd.read_csv(summary_file, sep=' ')\n",
    "    df = df[(df['sys'] == sys) & (df['i'] == run) & (df['itr'] == itr) & (df['dvfs'] == dvfs) \\\n",
    "            & (df['rapl'] == rapl) & (df['QPS_reported'] == qps)]\n",
    "    START = df['RDTSC_START']\n",
    "    if START.shape[0] == 0:\n",
    "        START = 0\n",
    "        END = 0\n",
    "    else:\n",
    "        START = START.values[0]\n",
    "        END = df['RDTSC_END'].values[0]\n",
    "    return START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee19fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_err_log(dvfs, qps, itr, err_dir, rapl='135', run='0'):\n",
    "    print()\n",
    "    err_filename = 'err_log_' + run + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "    if os.path.exists(err_dir + err_filename):\n",
    "        err_file = open(err_dir + err_filename, 'r')\n",
    "        print(err_file.read())\n",
    "    else:\n",
    "        print('EMPTY ERROR LOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d9dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_neg_diffs(df_diffs, df, core, err_file):\n",
    "    \n",
    "    tmp = df_diffs.copy()\n",
    "\n",
    "    # isolating rows with negative diffs\n",
    "    tmp_neg = tmp[(tmp['joules_diff'] < 0) | (tmp['instructions_diff'] < 0) | (tmp['cycles_diff'] < 0) \\\n",
    "                   | (tmp['ref_cycles_diff'] < 0) | (tmp['llc_miss_diff'] < 0) | (tmp['timestamp_diff'] < 0)]\n",
    "\n",
    "    # re-computing diffs if possible; else dropping rows\n",
    "    for i,j in tmp_neg.iterrows():\n",
    "        prev = df.shift(1).loc[i]\n",
    "        cur = df.loc[i]\n",
    "        # TODO note that we are only handling case of RAPL-energy-status register overflow\n",
    "        if (tmp.loc[i]['joules_diff'] < 0) & (tmp.loc[i]['timestamp_diff'] >= 0.001):\n",
    "            err_file.write('CORE ' + str(core) + '  ---  JOULES COUNTER OVERFLOW AT LOG ENTRY DIFF #' + str(i) + '\\n')\n",
    "            tmp.loc[i, ['joules_diff']] = (2**32 - 1) * joules_unit - prev['joules'] + cur['joules'] \n",
    "        else:\n",
    "            err_file.write('CORE ' + str(core) + '  ---  UNEXPLAINED NEGATIVE VALS AT LOG ENTRY DIFF # ' + str(i) + '\\n')\n",
    "            cols = ''\n",
    "            prevs = ''\n",
    "            currs = ''\n",
    "            for col in list(df.columns):\n",
    "                cols += col + '  '\n",
    "                prevs += str(prev[col]) + '  '\n",
    "                currs += str(cur[col]) + '  '\n",
    "            err_file.write('          ' + cols + '\\n')\n",
    "            err_file.write('         log[' + str(i-1) + ']: ' + prevs + '\\n')\n",
    "            err_file.write('         log[' + str(i) + ']: ' + currs + '\\n')\n",
    "            tmp = tmp.drop(i, axis=0)\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c32341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_merged_logs(merged_counters_df, merged_non_counters_df, dvfs, qps, itr, app, rapl='135', run='0'):\n",
    "    app_dir = app + '_' + run + '_rapl_' + rapl + '/'\n",
    "    merged_dir = app_dir + qps + '_merged/'\n",
    "    counters_df_outdir = merged_dir + qps + '_' + dvfs + '_counters_merged/'\n",
    "    non_counters_df_outdir = merged_dir + qps + '_' + dvfs + '_non_counters_merged/'\n",
    "    !mkdir -p $counters_df_outdir\n",
    "    !mkdir -p $non_counters_df_outdir\n",
    "    counters_outfile = counters_df_outdir + dvfs + '_' + qps + '_' + itr + '_counters_merged'\n",
    "    non_counters_outfile = non_counters_df_outdir + dvfs + '_' + qps + '_' + itr + '_non_counters_merged'\n",
    "    merged_counters_df.to_csv(counters_outfile)\n",
    "    merged_non_counters_df.to_csv(non_counters_outfile)\n",
    "    !gzip -v9 $counters_outfile\n",
    "    !gzip -v9 $non_counters_outfile\n",
    "\n",
    "    print(f'COUNTERS DIR: {counters_df_outdir}')\n",
    "    !ls $counters_df_outdir\n",
    "    print(f'NON_COUNTERS DIR: {non_counters_df_outdir}')\n",
    "    !ls $non_counters_df_outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e5711a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_merge_core_logs(dvfs, qps, itr, app, rapl='135', run='0'):\n",
    "    print(f'Concatenating and merging per-core logs (DVFS={dvfs} ITR-DELAY={itr}, QPS={qps})')\n",
    "    app_dir = app + '_' + run + '_rapl_' + rapl + '/'\n",
    "    logs_dir = app_dir + qps + '_qps/linux_' + app + '_dmesg_' + run + '_' + dvfs + '_' + rapl + '_' + qps + '/'\n",
    "    err_dir = app_dir + 'err_logs/'\n",
    "    err_filename = 'err_log_' + run + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "    err_file = open(err_dir + err_filename, 'w')\n",
    "\n",
    "    counters_full_df = pd.DataFrame()\n",
    "    non_counters_full_df = pd.DataFrame()    \n",
    "    df_merged_counters = pd.DataFrame()\n",
    "    df_merged_non_counters = pd.DataFrame()\n",
    "\n",
    "    # fetching experiment time syncing endpoints\n",
    "    rdtsc_dir = app_dir + qps + '_qps/linux_' + app +'_rdtsc_' + run + '_' + dvfs + '_' + rapl + '_' + qps +'/'\n",
    "    rdtsc_file = rdtsc_dir + 'linux.' + app + '.rdtsc.' + run + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "    start, end = eigen_analysis.get_rdtsc(rdtsc_file)\n",
    "    if ((start == 0) or (end == 0)):\n",
    "        if app == 'mcdsilo':\n",
    "            start, end = get_rdtsc_from_summary(app_dir + 'mcdsilo_combined.csv', 'linux', run, itr, dvfs, rapl, '50k')\n",
    "        if app == 'mcd':\n",
    "            # TODO\n",
    "            print('ALERT: MEMCACHED LOGS MISSING RDTSC DATA!')\n",
    "            print()\n",
    "    # abort if rdtsc endpoints are not found anywhere\n",
    "    if ((start == 0) or (end == 0)):\n",
    "        print('ALERT: Unable to sync log with START and END rdtsc timestamps...')\n",
    "        print('-------------------------------------------------- ABORTING -------------------------')\n",
    "        print()\n",
    "        abort = True\n",
    "        return df_merged_counters, df_merged_non_counters, abort\n",
    "    print(f'START_RDTSC = {start}, END_RDTSC = {end}')\n",
    "    abort = False\n",
    "\n",
    "    # concatenating then merging per-core logs\n",
    "    cores = []\n",
    "    cores = !ls $logs_dir | cut -d '_' -f2 | sort | uniq\n",
    "    for c in cores:\n",
    "        df_merged_counters = pd.DataFrame(columns=['instructions_diff', 'cycles_diff', 'ref_cycles_diff', \\\n",
    "                                     'llc_miss_diff', 'joules_diff', 'timestamp'])\n",
    "        df_merged_non_counters = pd.DataFrame(columns=['rx_bytes', 'rx_desc', 'tx_bytes', 'tx_desc', 'timestamp'])\n",
    "\n",
    "        log_file = logs_dir + 'linux.' + app + '.dmesg.' + run + '_' + str(c) + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "        !gunzip -v $log_file'.gz'        \n",
    "        df = pd.read_csv(log_file, sep = ' ', names = cols, index_col='i')\n",
    "        !gzip -v9 $log_file\n",
    "        df = df[(df['timestamp'] >= start) & (df['timestamp'] <= end)]\n",
    "        df.loc[:, 'timestamp'] = df['timestamp'] * time_unit\n",
    "        df.loc[:, 'joules'] = df['joules'] * joules_unit\n",
    "\n",
    "        # separating per-core log data into counter and non-counter data\n",
    "        # each occurring at different timescales (millisecond vs microsecond scale)\n",
    "        counters_df = df[['joules', 'instructions', 'cycles', 'ref_cycles', 'llc_miss', 'timestamp']].copy()\n",
    "        non_counters_df = df[['rx_bytes', 'rx_desc', 'tx_bytes', 'tx_desc', 'timestamp']].copy()                                                          \n",
    "\n",
    "        # computing counter data diffs \n",
    "        counters_df = counters_df[(counters_df['joules'] > 0) & (counters_df['instructions'] > 0) \\\n",
    "                                            & (counters_df['cycles'] > 0) & (counters_df['ref_cycles'] > 0) \\\n",
    "                                            & (counters_df['llc_miss'] > 0)]\n",
    "        timestamps = counters_df['timestamp'] # maintaining timestamps for merging across timestamp col     \n",
    "        df_diffs = counters_df.diff().dropna().copy()\n",
    "        df_diffs.columns = [f'{c}_diff' for c in df_diffs.columns]\n",
    "        df_diffs = handle_neg_diffs(df_diffs, counters_df, c, err_file)\n",
    "        df_diffs = df_diffs.drop(['timestamp_diff'], axis=1)\n",
    "        df_diffs['timestamp'] = timestamps    \n",
    "        \n",
    "        # merging counter data\n",
    "        if counters_full_df.shape[0] == 0:\n",
    "            counters_full_df = df_diffs.copy()\n",
    "        else:\n",
    "            counters_full_df = counters_full_df.merge(df_diffs, \\\n",
    "                                                      left_on = 'timestamp', \\\n",
    "                                                      right_on = 'timestamp', \\\n",
    "                                                      how='outer', \\\n",
    "                                                      sort=True, \\\n",
    "                                                      suffixes=('', '_0')).fillna(0) \n",
    "            for col in df_merged_counters.columns:\n",
    "                if col == 'timestamp':\n",
    "                    break\n",
    "                else:\n",
    "                    df_merged_counters[col] = (counters_full_df[[col, col+'_0']].sum(axis=1))    \n",
    "            df_merged_counters['timestamp'] = counters_full_df['timestamp']\n",
    "            counters_full_df = df_merged_counters.copy()\n",
    "            \n",
    "        # merging non-counter data\n",
    "        if non_counters_full_df.shape[0] == 0:\n",
    "            non_counters_full_df = non_counters_df.copy()\n",
    "        else:\n",
    "            non_counters_full_df = non_counters_full_df.merge(non_counters_df, \\\n",
    "                                                              left_on = 'timestamp', \\\n",
    "                                                              right_on = 'timestamp', \\\n",
    "                                                              how='outer', \\\n",
    "                                                              sort=True, \\\n",
    "                                                              suffixes=('', '_0')).fillna(0) \n",
    "            for col in df_merged_non_counters.columns:\n",
    "                if col == 'timestamp':\n",
    "                    break\n",
    "                else:\n",
    "                    df_merged_non_counters[col] = (non_counters_full_df[[col, col+'_0']].sum(axis=1))\n",
    "            df_merged_non_counters['timestamp'] = non_counters_full_df['timestamp']\n",
    "            non_counters_full_df = df_merged_non_counters.copy()\n",
    "                \n",
    "        print()\n",
    "        print('CORE: ', str(c))\n",
    "        print('         MERGED COUNTERS: ', df_merged_counters.shape)\n",
    "        print('         MERGED NON COUNTERS: ', df_merged_non_counters.shape)\n",
    "        \n",
    "    err_file.close()\n",
    "    if (os.path.getsize(err_dir + err_filename) == 0):\n",
    "        os.remove(err_dir + err_filename)\n",
    "        \n",
    "    print()\n",
    "    print('-------------------------------------------------- PARSED 16 LOGS -------------------------')\n",
    "    print()\n",
    "    return df_merged_counters, df_merged_non_counters, abort    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab789e4",
   "metadata": {},
   "source": [
    "### Merging per-core logs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59745cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = 'mcd'\n",
    "run = '0'\n",
    "rapl = '135'\n",
    "#dvfs = '0x1300'\n",
    "qps = '600k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e4edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dir = app + '_' + run + '_rapl_' + rapl + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52317daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcd_0_rapl_135/\n"
     ]
    }
   ],
   "source": [
    "print(app_dir)\n",
    "#print(logs_dir)\n",
    "#print(rdtsc_dir)\n",
    "#print(f'cores: {cores}')\n",
    "#print(f'itrs: {itrs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3daf58cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=100, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=40, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=400, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=10, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=250, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=200, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=300, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=30, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=350, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=20, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "\n",
      "merged log exists for (DVFS=0x1d00 ITR-DELAY=50, QPS=600k)..\n",
      "-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------\n",
      "\n",
      "Concatenating and merging per-core logs (DVFS=0x1d00 ITR-DELAY=2, QPS=600k)\n",
      "START_RDTSC = 5481278248154, END_RDTSC = 5539291934393\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_0_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_0_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_0_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_0_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  0\n",
      "         MERGED COUNTERS:  (0, 6)\n",
      "         MERGED NON COUNTERS:  (0, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_1_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_1_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_1_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_1_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  1\n",
      "         MERGED COUNTERS:  (39575, 6)\n",
      "         MERGED NON COUNTERS:  (3855357, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_10_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_10_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_10_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_10_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  10\n",
      "         MERGED COUNTERS:  (59356, 6)\n",
      "         MERGED NON COUNTERS:  (5766918, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_11_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_11_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_11_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_11_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  11\n",
      "         MERGED COUNTERS:  (79158, 6)\n",
      "         MERGED NON COUNTERS:  (7722729, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_12_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_12_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_12_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_12_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  12\n",
      "         MERGED COUNTERS:  (98944, 6)\n",
      "         MERGED NON COUNTERS:  (9633220, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_13_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_13_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_13_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_13_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  13\n",
      "         MERGED COUNTERS:  (118742, 6)\n",
      "         MERGED NON COUNTERS:  (11584847, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_14_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_14_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_14_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_14_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  14\n",
      "         MERGED COUNTERS:  (138529, 6)\n",
      "         MERGED NON COUNTERS:  (13504556, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_15_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_15_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_15_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_15_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  15\n",
      "         MERGED COUNTERS:  (158326, 6)\n",
      "         MERGED NON COUNTERS:  (15461266, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_2_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_2_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_2_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_2_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  2\n",
      "         MERGED COUNTERS:  (178110, 6)\n",
      "         MERGED NON COUNTERS:  (17373630, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_3_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_3_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_3_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_3_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  3\n",
      "         MERGED COUNTERS:  (197903, 6)\n",
      "         MERGED NON COUNTERS:  (19317390, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_4_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_4_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_4_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_4_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  4\n",
      "         MERGED COUNTERS:  (217686, 6)\n",
      "         MERGED NON COUNTERS:  (21231353, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_5_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_5_2_0x1d00_135_600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_5_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_5_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  5\n",
      "         MERGED COUNTERS:  (237482, 6)\n",
      "         MERGED NON COUNTERS:  (23176026, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_6_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_6_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_6_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_6_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  6\n",
      "         MERGED COUNTERS:  (257270, 6)\n",
      "         MERGED NON COUNTERS:  (25100564, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_7_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_7_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_7_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_7_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  7\n",
      "         MERGED COUNTERS:  (277067, 6)\n",
      "         MERGED NON COUNTERS:  (27044712, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_8_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_8_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_8_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_8_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  8\n",
      "         MERGED COUNTERS:  (296852, 6)\n",
      "         MERGED NON COUNTERS:  (28956603, 5)\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_9_2_0x1d00_135_600000.gz:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_9_2_0x1d00_135_600000\n",
      "mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_9_2_0x1d00_135_600000:\t 81.7% -- replaced with mcd_0_rapl_135/600k_qps/linux_mcd_dmesg_0_0x1d00_135_600k/linux.mcd.dmesg.0_9_2_0x1d00_135_600000.gz\n",
      "\n",
      "CORE:  9\n",
      "         MERGED COUNTERS:  (316649, 6)\n",
      "         MERGED NON COUNTERS:  (30909387, 5)\n",
      "\n",
      "-------------------------------------------------- PARSED 16 LOGS -------------------------\n",
      "\n",
      "\n",
      "CORE 1  ---  UNEXPLAINED NEGATIVE VALS AT LOG ENTRY DIFF # 10740\n",
      "          joules  instructions  cycles  ref_cycles  llc_miss  timestamp  \n",
      "         log[10739]: 197688.668911  191459719274.0  318663670018.0  356959010687.0  496315902.0  1890.188641732635  \n",
      "         log[10740]: 197272.98136099998  191164483888.0  318114912745.0  356397635038.0  489712626.0  1890.1893295728723  \n",
      "\n",
      "mcd_0_rapl_135/600k_merged/600k_0x1d00_counters_merged/0x1d00_600k_2_counters_merged:\t 66.4% -- replaced with mcd_0_rapl_135/600k_merged/600k_0x1d00_counters_merged/0x1d00_600k_2_counters_merged.gz\n",
      "mcd_0_rapl_135/600k_merged/600k_0x1d00_non_counters_merged/0x1d00_600k_2_non_counters_merged:\t 74.2% -- replaced with mcd_0_rapl_135/600k_merged/600k_0x1d00_non_counters_merged/0x1d00_600k_2_non_counters_merged.gz\n",
      "COUNTERS DIR: mcd_0_rapl_135/600k_merged/600k_0x1d00_counters_merged/\n",
      "0x1d00_600k_100_counters_merged.gz  0x1d00_600k_300_counters_merged.gz\n",
      "0x1d00_600k_10_counters_merged.gz   0x1d00_600k_30_counters_merged.gz\n",
      "0x1d00_600k_200_counters_merged.gz  0x1d00_600k_350_counters_merged.gz\n",
      "0x1d00_600k_20_counters_merged.gz   0x1d00_600k_400_counters_merged.gz\n",
      "0x1d00_600k_250_counters_merged.gz  0x1d00_600k_40_counters_merged.gz\n",
      "0x1d00_600k_2_counters_merged.gz    0x1d00_600k_50_counters_merged.gz\n",
      "NON_COUNTERS DIR: mcd_0_rapl_135/600k_merged/600k_0x1d00_non_counters_merged/\n",
      "0x1d00_600k_100_non_counters_merged.gz\t0x1d00_600k_300_non_counters_merged.gz\n",
      "0x1d00_600k_10_non_counters_merged.gz\t0x1d00_600k_30_non_counters_merged.gz\n",
      "0x1d00_600k_200_non_counters_merged.gz\t0x1d00_600k_350_non_counters_merged.gz\n",
      "0x1d00_600k_20_non_counters_merged.gz\t0x1d00_600k_400_non_counters_merged.gz\n",
      "0x1d00_600k_250_non_counters_merged.gz\t0x1d00_600k_40_non_counters_merged.gz\n",
      "0x1d00_600k_2_non_counters_merged.gz\t0x1d00_600k_50_non_counters_merged.gz\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skip_log = False\n",
    "#for dvfs in ['0xf00', '0x1100']:\n",
    "#for dvfs in ['0x1500', '0x1700']:\n",
    "for dvfs in ['0x1d00']:\n",
    "#, '0x1b00', '0x1d00']:\n",
    "#for dvfs in [dvfs]:\n",
    "    \n",
    "    for qps in [qps]:\n",
    "        logs_dir = app_dir + qps + '_qps/linux_' + app + '_dmesg_' + run + '_' + dvfs + '_' + rapl + '_' + qps + '/'\n",
    "        rdtsc_dir = app_dir + qps + '_qps/linux_' + app + '_rdtsc_' + run + '_' + dvfs + '_' + rapl + '_' + qps +'/'\n",
    "        \n",
    "        itrs = list_itrs(rdtsc_dir)\n",
    "        cores = []\n",
    "        cores = !ls $logs_dir | cut -d '_' -f2 | sort | uniq\n",
    "    \n",
    "        qps_dir = app_dir + qps + '_qps/'\n",
    "        merged_dir = app_dir + qps + '_merged/'\n",
    "        counters_df_outdir = merged_dir + qps + '_' + dvfs + '_counters_merged/'\n",
    "        non_counters_df_outdir = merged_dir + qps + '_' + dvfs + '_non_counters_merged/'\n",
    "        \n",
    "        for itr in itrs:\n",
    "            err_dir = app_dir + 'err_logs/'\n",
    "            err_filename = 'err_log_' + run + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "            err_file = open(err_dir + err_filename, 'w')\n",
    "            \n",
    "            skip_log = False\n",
    "            # check if merged log has been precomputed\n",
    "            counters_outfile = counters_df_outdir + dvfs + '_' + qps + '_' + itr + '_counters_merged'\n",
    "            non_counters_outfile = non_counters_df_outdir + dvfs + '_' + qps + '_' + itr + '_non_counters_merged'\n",
    "            if (os.path.exists(counters_outfile) or os.path.exists(counters_outfile + '.gz')):\n",
    "                if (os.path.exists(non_counters_outfile) or os.path.exists(non_counters_outfile + '.gz')):\n",
    "                    print()\n",
    "                    print(f'merged log exists for (DVFS={dvfs} ITR-DELAY={itr}, QPS={qps})..')\n",
    "                    print('-------------------------------------------------------------- PRE-PARSED 16 LOGS ---------------------')\n",
    "                    print()\n",
    "                    skip_log = True\n",
    "            \n",
    "            if (skip_log == True):\n",
    "                continue\n",
    "                \n",
    "            merged_counters_df, merged_non_counters_df, abort = concat_merge_core_logs(dvfs, qps, itr, app, run='0')\n",
    "            if (abort == True):\n",
    "                continue\n",
    "            \n",
    "            merged_counters_df['timestamp'] = merged_counters_df['timestamp'] - merged_counters_df['timestamp'].min()\n",
    "            merged_non_counters_df['timestamp'] = merged_non_counters_df['timestamp'] - merged_non_counters_df['timestamp'].min()\n",
    "\n",
    "            print_err_log(dvfs, qps, itr, err_dir)\n",
    "            save_merged_logs(merged_counters_df, merged_non_counters_df, dvfs, qps, itr, app, rapl='135', run='0')\n",
    "            print()\n",
    "            print('----------------------------------------')\n",
    "            print()\n",
    "            \n",
    "            err_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6adfe968",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructions_diff</th>\n",
       "      <th>cycles_diff</th>\n",
       "      <th>ref_cycles_diff</th>\n",
       "      <th>llc_miss_diff</th>\n",
       "      <th>joules_diff</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1032804.0</td>\n",
       "      <td>2368319.0</td>\n",
       "      <td>2426024.0</td>\n",
       "      <td>5616.0</td>\n",
       "      <td>0.253150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1087252.0</td>\n",
       "      <td>2746030.0</td>\n",
       "      <td>2876075.0</td>\n",
       "      <td>7528.0</td>\n",
       "      <td>0.206973</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1225372.0</td>\n",
       "      <td>2765001.0</td>\n",
       "      <td>2868216.0</td>\n",
       "      <td>7130.0</td>\n",
       "      <td>0.206973</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1198750.0</td>\n",
       "      <td>2777871.0</td>\n",
       "      <td>2879410.0</td>\n",
       "      <td>7176.0</td>\n",
       "      <td>0.206973</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1013150.0</td>\n",
       "      <td>2634384.0</td>\n",
       "      <td>2726783.0</td>\n",
       "      <td>7344.0</td>\n",
       "      <td>0.253150</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316644</th>\n",
       "      <td>509498.0</td>\n",
       "      <td>1485485.0</td>\n",
       "      <td>1485409.0</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>0.247538</td>\n",
       "      <td>20.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316645</th>\n",
       "      <td>533796.0</td>\n",
       "      <td>1428733.0</td>\n",
       "      <td>1428685.0</td>\n",
       "      <td>3039.0</td>\n",
       "      <td>0.247538</td>\n",
       "      <td>20.003187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316646</th>\n",
       "      <td>533315.0</td>\n",
       "      <td>1376728.0</td>\n",
       "      <td>1376688.0</td>\n",
       "      <td>3398.0</td>\n",
       "      <td>0.264740</td>\n",
       "      <td>20.003206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316647</th>\n",
       "      <td>595259.0</td>\n",
       "      <td>1611807.0</td>\n",
       "      <td>1611791.0</td>\n",
       "      <td>4182.0</td>\n",
       "      <td>0.247538</td>\n",
       "      <td>20.003210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316648</th>\n",
       "      <td>593764.0</td>\n",
       "      <td>1579648.0</td>\n",
       "      <td>1579601.0</td>\n",
       "      <td>3952.0</td>\n",
       "      <td>0.247538</td>\n",
       "      <td>20.003280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316649 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        instructions_diff  cycles_diff  ref_cycles_diff  llc_miss_diff  \\\n",
       "0               1032804.0    2368319.0        2426024.0         5616.0   \n",
       "1               1087252.0    2746030.0        2876075.0         7528.0   \n",
       "2               1225372.0    2765001.0        2868216.0         7130.0   \n",
       "3               1198750.0    2777871.0        2879410.0         7176.0   \n",
       "4               1013150.0    2634384.0        2726783.0         7344.0   \n",
       "...                   ...          ...              ...            ...   \n",
       "316644           509498.0    1485485.0        1485409.0         3353.0   \n",
       "316645           533796.0    1428733.0        1428685.0         3039.0   \n",
       "316646           533315.0    1376728.0        1376688.0         3398.0   \n",
       "316647           595259.0    1611807.0        1611791.0         4182.0   \n",
       "316648           593764.0    1579648.0        1579601.0         3952.0   \n",
       "\n",
       "        joules_diff  timestamp  \n",
       "0          0.253150   0.000000  \n",
       "1          0.206973   0.000002  \n",
       "2          0.206973   0.000015  \n",
       "3          0.206973   0.000020  \n",
       "4          0.253150   0.000022  \n",
       "...             ...        ...  \n",
       "316644     0.247538  20.003176  \n",
       "316645     0.247538  20.003187  \n",
       "316646     0.264740  20.003206  \n",
       "316647     0.247538  20.003210  \n",
       "316648     0.247538  20.003280  \n",
       "\n",
       "[316649 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_counters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "724717e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rx_bytes</th>\n",
       "      <th>rx_desc</th>\n",
       "      <th>tx_bytes</th>\n",
       "      <th>tx_desc</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403663</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403664</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403665</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403666</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403667</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1403668 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rx_bytes  rx_desc  tx_bytes  tx_desc  timestamp\n",
       "0            66.0      1.0      74.0      2.0   0.000000\n",
       "1            66.0      1.0      74.0      2.0   0.000023\n",
       "2            66.0      1.0      74.0      2.0   0.000045\n",
       "3            66.0      1.0      74.0      2.0   0.000065\n",
       "4            66.0      1.0      74.0      2.0   0.000086\n",
       "...           ...      ...       ...      ...        ...\n",
       "1403663       0.0      0.0      90.0      3.0  20.000213\n",
       "1403664      66.0      1.0       0.0      0.0  20.000214\n",
       "1403665      66.0      1.0       0.0      0.0  20.000220\n",
       "1403666      66.0      1.0     180.0      6.0  20.000225\n",
       "1403667      66.0      1.0       0.0      0.0  20.000226\n",
       "\n",
       "[1403668 rows x 5 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_non_counters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8220d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acda5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b374646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # given (dvfs, qps, itr), concatenate all per-core logs into one big dataframe\n",
    "# def concat_core_logs(dvfs, qps, itr, rapl='135', run='0'):\n",
    "#     print('Concatenating all per-core logs with ITR-DELAY = ', itr)\n",
    "    \n",
    "#     # here are all the log files for this dvfs & qps\n",
    "#     logs_dir = qps + '_qps/linux_mcd_dmesg_' + run + '_' + dvfs + '_' + rapl + '_' + qps + '/'\n",
    "#     # here are all the time-management files for this dvfs & qps\n",
    "#     rdtsc_dir = qps + '_qps/linux_mcd_rdtsc_' + run + '_' + dvfs + '_' + rapl + '_' + qps +'/'\n",
    "#     rdtsc_file = rdtsc_dir + 'linux.mcd.rdtsc.' + run + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "\n",
    "#     start, end = eigen_analysis.get_rdtsc(rdtsc_file)\n",
    "    \n",
    "#     # initializing error log file\n",
    "#     err_dir = 'err_logs/'\n",
    "#     err_filename = 'err_log_' + run + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "#     err_file = open(err_dir + err_filename, 'w')\n",
    "\n",
    "#     # here will be stored counter-based log data from all cores\n",
    "#     counters_full_df = pd.DataFrame()\n",
    "#     # here will be stored non-counter-based log data from all cores\n",
    "#     non_counters_full_df = pd.DataFrame()\n",
    "    \n",
    "#     # TODO remove fixed core-id range\n",
    "#     for c in range(0,16):\n",
    "#         file = logs_dir + 'linux.mcd.dmesg.' + run + '_' + str(c) + '_' + itr + '_' + dvfs + '_' + rapl + '_' + qps[:-1] + '000'\n",
    "#         df = pd.read_csv(file, sep = ' ', names = cols, index_col='i')\n",
    "#         df = df[(df['timestamp'] >= start) & (df['timestamp'] <= end)]\n",
    "#         df['timestamp'] = df['timestamp'] - df['timestamp'].min()\n",
    "#         df['timestamp'] = df['timestamp'] * time_unit\n",
    "#         df['joules'] = df['joules'] * joules_unit\n",
    "\n",
    "#         # CONCATENATING MILLISECOND-LEVEL PER-CORE DFS\n",
    "#         ##############################################\n",
    "#         # removing zero-filled log-entries\n",
    "#         # -> these represent interrupt occurrences at a frequency greater than per-1ms\n",
    "#         counters_df = df[['joules', 'instructions', 'cycles', 'ref_cycles', 'llc_miss', 'timestamp']].copy()\n",
    "#         counters_df = counters_df[(counters_df['joules'] > 0) & (counters_df['instructions'] > 0) \\\n",
    "#                                             & (counters_df['cycles'] > 0) & (counters_df['ref_cycles'] > 0) \\\n",
    "#                                             & (counters_df['llc_miss'] > 0)]\n",
    "\n",
    "#         tmp = counters_df['timestamp']        \n",
    "#         # computing diffs of counter readings\n",
    "#         df_diffs = counters_df.diff().dropna().copy()\n",
    "#         df_diffs.columns = [f'{c}_diff' for c in df_diffs.columns]\n",
    "#         df_diffs = handle_neg_diffs(df_diffs, counters_df, c, err_file)\n",
    "#         df_diffs = df_diffs.drop(['timestamp_diff'], axis=1)\n",
    "#         df_diffs['timestamp'] = tmp\n",
    "        \n",
    "#         if counters_full_df.shape[0] == 0:\n",
    "#             counters_full_df = df_diffs.copy()\n",
    "#         else:\n",
    "#             counters_full_df = counters_full_df.merge(df_diffs, \\\n",
    "#                                                       left_on = 'timestamp', \\\n",
    "#                                                       right_on = 'timestamp', \\\n",
    "#                                                       how='outer', \\\n",
    "#                                                       sort=True, \\\n",
    "#                                                       suffixes=('', '_0')).fillna(0)        \n",
    "\n",
    "#         # CONCATENATING MICROSECOND-LEVEL PER-CORE DFS\n",
    "#         ##############################################\n",
    "#         non_counters_df = df[['rx_bytes', 'rx_desc', 'tx_bytes', 'tx_desc', 'timestamp']].copy()                                                          \n",
    "\n",
    "#         if non_counters_full_df.shape[0] == 0:\n",
    "#             non_counters_full_df = non_counters_df.copy()\n",
    "#         else:\n",
    "#             non_counters_full_df = non_counters_full_df.merge(non_counters_df, \\\n",
    "#                                                               left_on = 'timestamp', \\\n",
    "#                                                               right_on = 'timestamp', \\\n",
    "#                                                               how='outer', \\\n",
    "#                                                               sort=True, \\\n",
    "#                                                               suffixes=('', '_0')).fillna(0)         \n",
    "            \n",
    "#         print('CORE: ', str(c))\n",
    "#         print('         NON COUNTERS:  full =', non_counters_df.shape[0], \\\n",
    "#               '  expected:', int(20 * 10**6 / int(itr)))        \n",
    "#         print('         COUNTERS:      full =', counters_df.shape[0], \\\n",
    "#               '  after computing diffs =', df_diffs.shape[0]          \\\n",
    "#              )\n",
    "\n",
    "#     # delete error log if empty\n",
    "#     err_file.close()\n",
    "#     if (os.path.getsize(err_dir + err_filename) == 0):\n",
    "#         os.remove(err_dir + err_filename)\n",
    "        \n",
    "#     print()\n",
    "#     print('-------------------------------------------------- PARSED 16 LOGS -------------------------')\n",
    "#     print()\n",
    "#     return counters_full_df, non_counters_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "89edb785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_concat_logs(counters_full_df, non_counters_full_df):\n",
    "    \n",
    "#     # creating dfs of average per-core log readings\n",
    "#     df_merged_counter = pd.DataFrame(columns=['instructions_diff', 'cycles_diff', 'ref_cycles_diff', \\\n",
    "#                                      'llc_miss_diff', 'joules_diff'])\n",
    "#     df_merged_non_counter = pd.DataFrame(columns=['rx_bytes', 'rx_desc', 'tx_bytes', 'tx_desc'])\n",
    "\n",
    "#     for col in df_merged_counter.columns:\n",
    "#         df_merged_counter[col] = (counters_full_df[[col, col+'_0']].sum(axis=1))\n",
    "#     df_merged_counter['timestamp'] = counters_full_df['timestamp']\n",
    "#     for col in df_merged_non_counter.columns:\n",
    "#         df_merged_non_counter[col] = (non_counters_full_df[[col, col+'_0']].sum(axis=1))\n",
    "#     df_merged_non_counter['timestamp'] = non_counters_full_df['timestamp']\n",
    "    \n",
    "#     return df_merged_counter, df_merged_non_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
